{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "import spotipy.util as util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "\n",
    "import PIL.Image\n",
    "from pylab import *\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'         #<----------------- YOUR ID HERE\n",
    "    \n",
    "client_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'       #<----------------- YOUR SECRET HERE\n",
    "\n",
    "username = 'XXXXXXXXXXXXXX'                                #<----------------- YOUR USERNAME HERE\n",
    "\n",
    "scope = 'playlist-modify-public playlist-modify'\n",
    "\n",
    "redirect_uri = 'https://developer.spotify.com/dashboard/applications/0b03809ce8db4dd785536aad89af792b'\n",
    "\n",
    "token = util.prompt_for_user_token(username=username, \n",
    "                                   scope=scope, \n",
    "                                   client_id=client_id,   \n",
    "                                   client_secret=client_secret,     \n",
    "                                   redirect_uri=redirect_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for All Podcasts Related to Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Spotify’s catalog for content: \n",
    "\n",
    "# The search API now returns podcast shows and episodes. \n",
    "# Set the type parameter to show or episode to query these new types of content.\n",
    "\n",
    "\n",
    "\n",
    "# GET https://api.spotify.com/v1/search \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter a term to search below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter term to search here\n",
    "\n",
    "search = 'data science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search endpoint\n",
    "\n",
    "endpoint_url = \"https://api.spotify.com/v1/search?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM THE QUERY\n",
    "\n",
    "id_list = []\n",
    "name_list = []                                         # create empty lists to hold data\n",
    "desc_list = []\n",
    "\n",
    "type = 'show'    \n",
    "market  = 'US'\n",
    "limit = 50                                             # assign variables for search query\n",
    "offset = 0                                             # start offset at 0\n",
    "\n",
    "\n",
    "more_runs = 1                                          # instantiate conditional variables\n",
    "counter = 0  \n",
    "\n",
    "                                                            # max offset is 2000 including limit\n",
    "while((offset <= 1950) & (counter <= more_runs)):           # while loop to run with conditional variables\n",
    "\n",
    "\n",
    "\n",
    "    query = f'{endpoint_url}'\n",
    "    query += f'&q={search}'\n",
    "    query += f'&type={type}'\n",
    "    query += f'&offset={offset}'                       # format search query with assigned variables\n",
    "    query += f'&market={market}'\n",
    "    query += f'&limit={limit}'\n",
    "\n",
    "\n",
    "    response = requests.get(query,                                           # get request\n",
    "                   headers={\"Content-Type\":\"application/json\", \n",
    "                            \"Authorization\":f\"Bearer {token}\"})  \n",
    "    json_response = response.json()                                           # as a json file\n",
    "\n",
    "\n",
    "    for i in range(len(json_response['shows']['items'])):                      # loop through json\n",
    "\n",
    "        id_list.append(json_response['shows']['items'][i]['id'])               # pull out info from json\n",
    "        name_list.append(json_response['shows']['items'][i]['name'])           # into empty lists\n",
    "        desc_list.append(json_response['shows']['items'][i]['description'])\n",
    "        \n",
    "        \n",
    "    more_runs = (json_response['shows']['total'] // 50 )            # how many more runs of 50 are needed?       \n",
    "        \n",
    "    counter += 1                                                    # increase conditional counter by 1\n",
    "    \n",
    "    offset = offset + 50                                            # increase offset by 50\n",
    "\n",
    "                                                                    # rinse and repeat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dataframe from the lists\n",
    "\n",
    "podcasts = pd.DataFrame()\n",
    "\n",
    "podcasts['id'] = id_list\n",
    "podcasts['name'] = name_list\n",
    "podcasts['description'] = desc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63diy2DtpHzQfeNVxAPZgU</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>Sharing concepts, ideas, and codes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1LaCr5TFAgYPK5qHjP3XDp</td>\n",
       "      <td>Practical AI: Machine Learning &amp; Data Science</td>\n",
       "      <td>Making artificial intelligence practical, prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0kp4abozqxCmILx0lT9foc</td>\n",
       "      <td>The SCP Foundation Database</td>\n",
       "      <td>An immersive audio storytelling series from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5nrspdHxUxzc9TkEibpxD5</td>\n",
       "      <td>Data Science Now</td>\n",
       "      <td>Data Science Now is a podcast brought to you b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71RbIpffwWXUMZQTFKiMWk</td>\n",
       "      <td>The Artists of Data Science</td>\n",
       "      <td>In his book Linchpin, Seth Godin says that \"“A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1c5P5abWTtAt8YoRFvwEtD</td>\n",
       "      <td>The AI Saga with Himanshu</td>\n",
       "      <td>Human Stimuli to AI and Beyond. Talk on Artifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>3exqoUpUguDVxFIsoktbh3</td>\n",
       "      <td>Tasos Random Sound Experience</td>\n",
       "      <td>I record random thoughts that I believe are wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>03pNYD62pifRnpR0Ljs7Lj</td>\n",
       "      <td>GI Insights</td>\n",
       "      <td>GI Insights is dedicated to advancing the scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2puy6CmE3kXAr2S5INkfIq</td>\n",
       "      <td>Journey To The Edge Of Machine Learning</td>\n",
       "      <td>This is a learning journal where I record the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>7nzU65DlqCHyvS2srkmjIh</td>\n",
       "      <td>What Supp</td>\n",
       "      <td>NFL Veteran Jared Veldheer takes his backgroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                                           name  \\\n",
       "0    63diy2DtpHzQfeNVxAPZgU                           Towards Data Science   \n",
       "1    1LaCr5TFAgYPK5qHjP3XDp  Practical AI: Machine Learning & Data Science   \n",
       "2    0kp4abozqxCmILx0lT9foc                    The SCP Foundation Database   \n",
       "3    5nrspdHxUxzc9TkEibpxD5                               Data Science Now   \n",
       "4    71RbIpffwWXUMZQTFKiMWk                    The Artists of Data Science   \n",
       "..                      ...                                            ...   \n",
       "276  1c5P5abWTtAt8YoRFvwEtD                      The AI Saga with Himanshu   \n",
       "277  3exqoUpUguDVxFIsoktbh3                 Tasos Random Sound Experience    \n",
       "278  03pNYD62pifRnpR0Ljs7Lj                                    GI Insights   \n",
       "279  2puy6CmE3kXAr2S5INkfIq        Journey To The Edge Of Machine Learning   \n",
       "280  7nzU65DlqCHyvS2srkmjIh                                      What Supp   \n",
       "\n",
       "                                           description  \n",
       "0                   Sharing concepts, ideas, and codes  \n",
       "1    Making artificial intelligence practical, prod...  \n",
       "2    An immersive audio storytelling series from th...  \n",
       "3    Data Science Now is a podcast brought to you b...  \n",
       "4    In his book Linchpin, Seth Godin says that \"“A...  \n",
       "..                                                 ...  \n",
       "276  Human Stimuli to AI and Beyond. Talk on Artifi...  \n",
       "277  I record random thoughts that I believe are wo...  \n",
       "278  GI Insights is dedicated to advancing the scie...  \n",
       "279  This is a learning journal where I record the ...  \n",
       "280  NFL Veteran Jared Veldheer takes his backgroun...  \n",
       "\n",
       "[281 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a full list of show ID's to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all show ids for later\n",
    "\n",
    "show_list = list(podcasts['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List All Episodes for One Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List episodes for a show: \n",
    "\n",
    "\n",
    "# GET https://api.spotify.com/v1/shows/{id}/episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM THE QUERY\n",
    "\n",
    "id = '1n8P7ZSgfVLVJ3GegxPat1'       #<------------------------------------ INSERT SHOW ID MANUALLY\n",
    "type = 'episodes'\n",
    "market  = 'US'\n",
    "limit = 50\n",
    "offset = 0\n",
    "\n",
    "id_list = []\n",
    "dur_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "desc_list = []\n",
    "\n",
    "counter = 0\n",
    "more_runs = 1\n",
    "\n",
    "while(counter <= more_runs):\n",
    "\n",
    "\n",
    "    endpoint_url = f\"https://api.spotify.com/v1/shows/{id}/episodes?\"\n",
    "\n",
    "\n",
    "    query = f'{endpoint_url}'\n",
    "    query += f'&q={search}'\n",
    "    query += f'&type={type}'\n",
    "    query += f'&offset={offset}'\n",
    "    query += f'&market={market}'\n",
    "    query += f'&limit={limit}'\n",
    "\n",
    "\n",
    "    response = requests.get(query, \n",
    "                   headers={\"Content-Type\":\"application/json\", \n",
    "                            \"Authorization\":f\"Bearer {token}\"})\n",
    "    json_response = response.json()\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(json_response['items'])):\n",
    "\n",
    "        id_list.append(json_response['items'][i]['id'])\n",
    "        dur_list.append(json_response['items'][i]['duration_ms'])\n",
    "        date_list.append(json_response['items'][i]['release_date'])    \n",
    "        name_list.append(json_response['items'][i]['name'])\n",
    "        desc_list.append(json_response['items'][i]['description'])\n",
    "        \n",
    "        \n",
    "    more_runs = (json_response['total'] // 50 )         \n",
    "        \n",
    "    counter += 1\n",
    "    \n",
    "    offset = offset + 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a dataframe from the lists\n",
    "\n",
    "episodes = pd.DataFrame()\n",
    "\n",
    "episodes['id'] = id_list\n",
    "episodes['length(ms)'] = dur_list\n",
    "episodes['date'] = date_list\n",
    "episodes['name'] = name_list\n",
    "episodes['description'] = desc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List All Episodes for Multiple Shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List episodes for a show: \n",
    "\n",
    "\n",
    "# GET https://api.spotify.com/v1/shows/{id}/episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM THE QUERY\n",
    "\n",
    "show_id_list = []                                       # create empty lists to hold data\n",
    "id_list = []\n",
    "dur_list = []\n",
    "date_list = []\n",
    "name_list = []\n",
    "desc_list = []\n",
    "\n",
    "\n",
    "for show_id in show_list:                               # for loop to iterate through every show in show_list\n",
    "       \n",
    "    more_runs = 1                                       # instantiate conditional variables\n",
    "    counter = 0    \n",
    "    \n",
    "    id = show_id                                        # assign variables for search query\n",
    "    type = 'episodes'\n",
    "    market  = 'US'                                      # start the offset at 0\n",
    "    limit = 50\n",
    "    offset = 0                                \n",
    "\n",
    "                                                             # max offset is 2000 including limit\n",
    "    while((offset <= 1950) & (counter <= more_runs)):        # while loop to run with conditional variables\n",
    "    \n",
    "        endpoint_url = f\"https://api.spotify.com/v1/shows/{id}/episodes?\"\n",
    "\n",
    "        query = f'{endpoint_url}'\n",
    "        query += f'&q={search}'                              # format the query with assigned variables\n",
    "        query += f'&type={type}'\n",
    "        query += f'&offset={offset}'\n",
    "        query += f'&market={market}'\n",
    "        query += f'&limit={limit}'\n",
    "\n",
    "\n",
    "        response = requests.get(query,                                      # get request\n",
    "                       headers={\"Content-Type\":\"application/json\", \n",
    "                                \"Authorization\":f\"Bearer {token}\"})\n",
    "        json_response = response.json()                                     # as a json file\n",
    "               \n",
    "            \n",
    "        \n",
    "        if next(iter(json_response)) == 'error':                            # if there's an error\n",
    "                                                                            # and it's because of an id error\n",
    "            if json_response['error']['message'] != 'non existing id':      # move onto the next id       \n",
    "                break                                     \n",
    "            else:\n",
    "                continue            \n",
    "\n",
    "        for i in range(len(json_response['items'])):                        # loop through json\n",
    "\n",
    "            show_id_list.append(show_id)\n",
    "            id_list.append(json_response['items'][i]['id'])                 # pull out info from json\n",
    "            dur_list.append(json_response['items'][i]['duration_ms'])       # into empty lists\n",
    "            date_list.append(json_response['items'][i]['release_date'])    \n",
    "            name_list.append(json_response['items'][i]['name'])\n",
    "            desc_list.append(json_response['items'][i]['description'])\n",
    "            \n",
    "            \n",
    "        more_runs = (json_response['total'] // 50 )              # how many more runs of 50 are needed?\n",
    "\n",
    "        offset = offset + 50                                     # increase the offset by 50\n",
    "        \n",
    "        counter += 1                                             # increase the counter by 1\n",
    "    \n",
    "        if json_response['total'] < 50:                 # if it only needs one run then exit the while loop\n",
    "      \n",
    "            break                                       # rinse and repeat!\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a dataframe from the lists\n",
    "\n",
    "all_episodes = pd.DataFrame()\n",
    "\n",
    "all_episodes['show_id'] = show_id_list\n",
    "all_episodes['episode_id'] = id_list\n",
    "all_episodes['length(ms)'] = dur_list\n",
    "all_episodes['date'] = date_list\n",
    "all_episodes['episode_name'] = name_list\n",
    "all_episodes['description'] = desc_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert corresponding Show Name for every Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of show ids and show names\n",
    "\n",
    "fmap = podcasts.groupby('id')['name'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map dictionary to show id in dataframe\n",
    "\n",
    "all_episodes['show_id'] = all_episodes['show_id'].map(fmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the show id column to show name\n",
    "\n",
    "all_episodes.rename(columns = {'show_id':'show_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the brackets [] from each show name\n",
    "\n",
    "all_episodes['show_name'] = all_episodes['show_name'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv file\n",
    "\n",
    "all_episodes.to_csv('podcasts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Some Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set background to dark\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "for param in ['text.color', 'axes.labelcolor', 'xtick.color', 'ytick.color']:\n",
    "    plt.rcParams[param] = '#cccccc'  # very light grey\n",
    "\n",
    "for param in ['figure.facecolor', 'axes.facecolor', 'savefig.facecolor']:\n",
    "    plt.rcParams[param] = '#404040'  # dark grey\n",
    "    \n",
    "plt.rcParams['axes.axisbelow'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of each show\n",
    "\n",
    "episode_count = all_episodes['show_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep shows with more than 100 episodes\n",
    "\n",
    "episode_count = episode_count.where(lambda x : x>=100).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to int\n",
    "\n",
    "episode_count = episode_count.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to dataframe\n",
    "\n",
    "podcasts_top100 = pd.DataFrame(episode_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "cmap = sns.color_palette(\"YlGn\", 25)\n",
    "\n",
    "ax = sns.barplot(x = podcasts_top100.show_name , y = podcasts_top100.index , data = podcasts_top100, orient = 'h', palette=cmap, edgecolor=cmap)\n",
    "\n",
    "plt.xticks(np.arange(0, 420, 20), size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.ylabel('')\n",
    "plt.title('\"Data Science\" Podcasts with More Than 100 Episodes',fontsize=30)\n",
    "plt.xlabel('Number of Episodes', fontsize=15)\n",
    "plt.grid(color='#4d4d4d')\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert milliseconds to minutes (rounded)\n",
    "\n",
    "all_episodes['length(ms)'] = round((all_episodes['length(ms)'] / 1000)/60, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column name to minutes\n",
    "\n",
    "all_episodes.rename(columns = {'length(ms)':'length(m)'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length distribution\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "sns.kdeplot(all_episodes['length(m)'], shade = True, color = 'limegreen', legend = False )\n",
    "\n",
    "plt.title('Length of All \"Data Science\" Episodes', fontsize = 20)\n",
    "plt.xlabel('Length in Minutes', fontsize=16)\n",
    "plt.xticks(np.arange(0, 340, 10), size=10)\n",
    "plt.ylabel('Density', fontsize=16)\n",
    "plt.grid(color='#4d4d4d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average episode length for each show\n",
    "\n",
    "show_length = all_episodes.groupby('show_name').mean().sort_values('length(m)', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg length distribution\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "sns.kdeplot(show_length['length(m)'], shade = True, color = 'limegreen', legend= False )\n",
    "\n",
    "plt.title(\"Average Length of Each 'Data Science' Show's Episodes\", fontsize = 20)\n",
    "plt.xlabel('Length in Minutes', fontsize=16)\n",
    "plt.xticks(np.arange(0, 180, 10), size=10)\n",
    "plt.ylabel('Density', fontsize=16)\n",
    "plt.grid(color='#4d4d4d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the top 20\n",
    "\n",
    "show_length = show_length.iloc[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "cmap = sns.color_palette(\"YlGn\", 25)\n",
    "\n",
    "ax = sns.barplot(x = show_length['length(m)'] , y = show_length.index , data = show_length, orient = 'h', palette=cmap, edgecolor=cmap)\n",
    "\n",
    "plt.xticks(np.arange(0, 150, 10), size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.ylabel('')\n",
    "plt.title('The 20 Longest \"Data Science\" Podcasts on Average',fontsize=30)\n",
    "plt.xlabel('Average Length of an Episode (minutes)', fontsize=15)\n",
    "plt.grid(color='#4d4d4d')\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime\n",
    "\n",
    "all_episodes['date'] = pd.to_datetime(all_episodes['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index\n",
    "\n",
    "all_episodes.index = all_episodes['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total by month\n",
    "\n",
    "month_count = all_episodes.resample('M').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(20,6))\n",
    "\n",
    "n_shades = 10\n",
    "diff_linewidth = 2.5\n",
    "alpha_value = 0.2 / n_shades\n",
    "\n",
    "\n",
    "ax1 = month_count.plot(marker='o', y= 'date', ax=ax1, color='limegreen', legend=False)\n",
    "\n",
    "for n in range(1, n_shades+1):\n",
    "    month_count.plot(marker='o', linewidth=2+(diff_linewidth*n),\n",
    "            alpha=alpha_value, ax=ax1, legend=False, color='limegreen')\n",
    "\n",
    "plt.fill_between(x=month_count.index, y1=month_count['date'].values, y2=[0] * len(month_count), color='limegreen', alpha=0.3)    \n",
    "\n",
    "plt.ylabel('Number of Shows')\n",
    "plt.xlabel('')\n",
    "plt.title('Timeline of Total \"Data Science\" Shows per Month', fontsize=20)\n",
    "plt.grid(color='#4d4d4d')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total by year and reset index\n",
    "\n",
    "year_count = all_episodes.resample('Y').count()\n",
    "year_count = year_count['show_name']\n",
    "year_count = year_count.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "year = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "cmap = sns.color_palette(\"YlGn\", 12)\n",
    "\n",
    "g = sns.barplot(x = year , y = year_count.values , data = year_count, orient = 'v', palette=cmap, edgecolor=cmap)\n",
    "\n",
    "plt.xticks(np.arange(0, 8, 1), size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.ylabel('')\n",
    "plt.title('Total Number of \"Data Science\" Podcasts per Year',fontsize=30)\n",
    "plt.xlabel('Year', fontsize=15)\n",
    "plt.grid(color='#4d4d4d')\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "\n",
    "for index, row in year_count.iteritems():\n",
    "    g.text(index  , row + 50, row, color='#cccccc', ha=\"center\", fontsize=15)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only episodes in 2020\n",
    "\n",
    "all_episodes_2020 = all_episodes[all_episodes['date'].dt.strftime('%Y') == '2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total for each day\n",
    "\n",
    "all_episodes_2020 = all_episodes_2020.resample('D').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(20,6))\n",
    "\n",
    "n_shades = 10\n",
    "diff_linewidth = 2.5\n",
    "alpha_value = 0.2 / n_shades\n",
    "\n",
    "\n",
    "ax1 = all_episodes_2020.plot(marker='o', y= 'date', ax=ax1, color='limegreen', legend=False)\n",
    "\n",
    "for n in range(1, n_shades+1):\n",
    "    all_episodes_2020.plot(marker='o', linewidth=2+(diff_linewidth*n),\n",
    "            alpha=alpha_value, ax=ax1, legend=False, color='limegreen')\n",
    "\n",
    "plt.fill_between(x=all_episodes_2020.index, y1=all_episodes_2020['date'].values, y2=[0] * len(all_episodes_2020), color='limegreen', alpha=0.3)    \n",
    "\n",
    "plt.ylabel('Number of Shows')\n",
    "plt.xlabel('')\n",
    "plt.title('Timeline of \"Data Science\" Shows in 2020', fontsize=20)\n",
    "plt.grid(color='#4d4d4d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total for each day\n",
    "\n",
    "weekday = all_episodes.resample('D').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index to day of the week\n",
    "\n",
    "weekday['weekday'] = weekday.index.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total number of episode per day and reorder the index\n",
    "\n",
    "weekday_total = weekday.groupby('weekday').sum()\n",
    "weekday_total = weekday_total.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "\n",
    "weekday_total = weekday_total.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "cmap = sns.color_palette(\"YlGn\", 9)\n",
    "\n",
    "g = sns.barplot(x = weekday_total.weekday , y = weekday_total['date'].values , data = weekday_total, orient = 'v', palette=cmap, edgecolor=cmap)\n",
    "\n",
    "plt.xticks(np.arange(0, 7, 1), size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.ylabel('')\n",
    "plt.title('Total Number of \"Data Science\" Podcasts per Weekday',fontsize=30)\n",
    "plt.xlabel('')\n",
    "plt.grid(color='#4d4d4d')\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "for index, row in weekday_total['date'].iteritems():\n",
    "    g.text(index  , row + 30, row, color='#cccccc', ha=\"center\", fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average number of shows per weekday and reorder \n",
    "\n",
    "weekday_avg = weekday.groupby('weekday').mean()\n",
    "weekday_avg = weekday_avg.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "\n",
    "weekday_avg = weekday_avg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "cmap = sns.color_palette(\"YlGn\", 9)\n",
    "\n",
    "g = sns.barplot(x = weekday_avg.weekday , y = weekday_avg['date'].values , data = weekday_avg, orient = 'v', palette=cmap, edgecolor=cmap)\n",
    "\n",
    "plt.xticks(np.arange(0, 7, 1), size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.ylabel('')\n",
    "plt.title('Average Number of \"Data Science\" Podcasts per Weekday',fontsize=30)\n",
    "plt.xlabel('')\n",
    "plt.grid(color='#4d4d4d')\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "for index, row in weekday_avg['date'].iteritems():\n",
    "    g.text(index  , row + 0.1, round(row, 2), color='#cccccc', ha=\"center\", fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wordbank from descriptions\n",
    "\n",
    "wordbank = all_episodes['description'].unique()\n",
    "\n",
    "wordbank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a word cloud\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "wordcloud = WordCloud(background_color='white', stopwords=stopwords, max_words=1000, width=2000, height=1000).generate(' '.join(str(word) for word in wordbank))\n",
    "\n",
    "# display the word cloud\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(20) # set width\n",
    "fig.set_figheight(20) # set height\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open image (just make sure it's in your working directory) and save mask to book\n",
    "\n",
    "mic = np.array(PIL.Image.open('mic.png'))\n",
    "\n",
    "imshow(mic)\n",
    "\n",
    "print('Image opened and saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display mask image\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(10) # set width\n",
    "fig.set_figheight(10) # set height\n",
    "\n",
    "plt.imshow(mic, cmap=plt.cm.gray, interpolation='None')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a beautiful wordcloud\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=3000, mask=mic,\n",
    "               stopwords=stopwords, max_font_size=60, random_state=42)\n",
    "# generate word cloud\n",
    "wc.generate(' '.join(wordbank))\n",
    "\n",
    "# create coloring from image\n",
    "image_colors = ImageColorGenerator(mic)\n",
    "\n",
    "# show\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# recolor wordcloud and show\n",
    "# we could also give color_func=image_colors directly in the constructor\n",
    "plt.imshow(wc.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format text to lowercase and remove any numbers, reset the index\n",
    "\n",
    "all_episodes = all_episodes.reset_index(drop=True)\n",
    "\n",
    "text = all_episodes['description'].str.lower()\n",
    "text = text.str.replace('\\d+', '')\n",
    "text = text.astype('str')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 models\n",
    "\n",
    "text_model_1 = markovify.NewlineText(text, state_size = 3)\n",
    "text_model_2 = markovify.NewlineText(text, state_size = 3)\n",
    "text_model_3 = markovify.NewlineText(text, state_size = 3)\n",
    "text_model_4 = markovify.NewlineText(text, state_size = 3)\n",
    "text_model_5 = markovify.NewlineText(text, state_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model ensemble and generate 10 new episode descriptions\n",
    "\n",
    "model_combo = markovify.combine([ text_model_1, text_model_2, text_model_3, text_model_4, text_model_5 ], [ 1, 1, 1, 1, 1])\n",
    "\n",
    "# Print randomly-generated sentences using the built model\n",
    "\n",
    "for idx, i in enumerate(range(10)):\n",
    "    print('(',idx+1,')','   ', model_combo.make_sentence(tries=10000, max_overlap_ratio = 0.2, test_output= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
